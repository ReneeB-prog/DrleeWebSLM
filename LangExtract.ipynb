{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PHVwbyTIKrgKB5lbfrukfjY5pGpL8pN-",
      "authorship_tag": "ABX9TyMdo02QytaZTFp4S2UAH8F8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReneeB-prog/DrleeWebSLM/blob/main/LangExtract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "R_IRu_6-QGKB"
      },
      "outputs": [],
      "source": [
        "# Make sure to add your GEMINI_API_KEY in Colab secrets first!\n",
        "\n",
        "# Step 1: Install all dependencies\n",
        "!pip install -q google-generativeai gradio pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import all libraries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from google.colab import userdata\n",
        "from google import generativeai as genai\n",
        "from typing import List, Optional\n",
        "from dataclasses import dataclass, field\n",
        "import io"
      ],
      "metadata": {
        "id": "lVfXGX3kS83R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Configure Gemini\n",
        "print(\"üîÑ Configuring Gemini...\")\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "print(\"‚úÖ Gemini configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsk8dKroTDI_",
        "outputId": "3778cb26-e513-4e3a-9de3-3fd0f2f811e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Configuring Gemini...\n",
            "‚úÖ Gemini configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Download sample books from Project Gutenberg\n",
        "print(\"\\nüìö Downloading sample books...\")\n",
        "book_urls = [\n",
        "    \"https://www.gutenberg.org/files/1342/1342-0.txt\",  # Pride and Prejudice\n",
        "    \"https://www.gutenberg.org/files/11/11-0.txt\",      # Alice in Wonderland\n",
        "    \"https://www.gutenberg.org/files/84/84-0.txt\",       # Frankenstein\n",
        "    \"https://www.gutenberg.org/files/1661/1661-0.txt\",   # Sherlock Holmes\n",
        "    \"https://www.gutenberg.org/files/98/98-0.txt\",       # Tale of Two Cities\n",
        "    \"https://www.gutenberg.org/files/844/844-0.txt\",     # Dorian Gray\n",
        "    \"https://www.gutenberg.org/files/2701/2701-0.txt\",   # Moby Dick\n",
        "    \"https://www.gutenberg.org/files/345/345-0.txt\",     # Dracula\n",
        "    \"https://www.gutenberg.org/files/1232/1232-0.txt\",   # The Prince\n",
        "    \"https://www.gutenberg.org/files/2591/2591-0.txt\"    # Grimm's Fairy Tales\n",
        "]\n",
        "\n",
        "books_content = {}\n",
        "for url in book_urls:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        book_name = url.split('/')[-1].replace('-0.txt', '')\n",
        "        books_content[book_name] = response.text[:50000]  # First 50k chars\n",
        "        print(f\"  ‚úì Downloaded book ID: {book_name}\")\n",
        "    except:\n",
        "        print(f\"  ‚úó Failed to download: {url}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Downloaded {len(books_content)} books successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAZeK1mSTHYS",
        "outputId": "9ab7e809-7bbc-4f68-8405-1e6df8036783"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìö Downloading sample books...\n",
            "  ‚úì Downloaded book ID: 1342\n",
            "  ‚úì Downloaded book ID: 11\n",
            "  ‚úì Downloaded book ID: 84\n",
            "  ‚úì Downloaded book ID: 1661\n",
            "  ‚úì Downloaded book ID: 98\n",
            "  ‚úì Downloaded book ID: 844\n",
            "  ‚úì Downloaded book ID: 2701\n",
            "  ‚úì Downloaded book ID: 345\n",
            "  ‚úì Downloaded book ID: 1232\n",
            "  ‚úì Downloaded book ID: 2591\n",
            "\n",
            "‚úÖ Downloaded 10 books successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define extraction schema\n",
        "@dataclass\n",
        "class BookMetadata:\n",
        "    \"\"\"Schema for extracting structured data from books\"\"\"\n",
        "    title: str\n",
        "    author: str\n",
        "    publication_year: Optional[int]\n",
        "    main_characters: List[str]\n",
        "    setting_location: str\n",
        "    genre: str\n",
        "    plot_summary: str\n",
        "    major_themes: List[str]\n",
        "    opening_line: str\n",
        "    target_audience: str\n",
        "\n",
        "def create_extraction_prompt(text_sample):\n",
        "    \"\"\"Create a structured prompt for Gemini to extract book metadata\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this book excerpt and extract the following information.\n",
        "    Return ONLY a valid JSON object with these exact fields:\n",
        "\n",
        "    {{\n",
        "        \"title\": \"exact title of the book\",\n",
        "        \"author\": \"full author name\",\n",
        "        \"publication_year\": year as integer or null,\n",
        "        \"main_characters\": [\"character1\", \"character2\", ...] (max 5),\n",
        "        \"setting_location\": \"primary geographic setting\",\n",
        "        \"genre\": \"primary genre classification\",\n",
        "        \"plot_summary\": \"concise plot summary in exactly 100 words\",\n",
        "        \"major_themes\": [\"theme1\", \"theme2\", ...] (max 3),\n",
        "        \"opening_line\": \"the memorable opening line\",\n",
        "        \"target_audience\": \"intended reader demographic\"\n",
        "    }}\n",
        "\n",
        "    Book excerpt:\n",
        "    {text_sample}\n",
        "\n",
        "    JSON Output:\n",
        "    \"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "lC0Z0u5ETRwb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create extraction functions\n",
        "def extract_with_langextract(text, progress_callback=None):\n",
        "    \"\"\"Extract structured data using LangExtract pattern with Gemini\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate extraction prompt\n",
        "        prompt = create_extraction_prompt(text)\n",
        "\n",
        "        # Call Gemini for extraction\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config={\n",
        "                \"temperature\": 0.1,\n",
        "                \"top_p\": 0.95,\n",
        "                \"max_output_tokens\": 2048, # Increased max_output_tokens\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Check if response is valid and not blocked\n",
        "        if not response.candidates or not response.candidates[0].content.parts:\n",
        "             if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
        "                print(f\"  ‚úó Extraction error: Content blocked due to: {response.prompt_feedback.block_reason}\")\n",
        "             else:\n",
        "                print(f\"  ‚úó Extraction error: No valid content in response. Full response: {response}\") # Added full response print\n",
        "             return None\n",
        "\n",
        "        # Parse JSON response\n",
        "        json_text = response.candidates[0].content.parts[0].text\n",
        "        if \"```json\" in json_text:\n",
        "            json_text = json_text.split(\"```json\")[1].split(\"```\")[0]\n",
        "        elif \"```\" in json_text:\n",
        "            json_text = json_text.split(\"```\")[1].split(\"```\")[0]\n",
        "        else:\n",
        "            # If no code block is found, assume the entire response is JSON\n",
        "            pass\n",
        "\n",
        "\n",
        "        extracted_data = json.loads(json_text.strip())\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback()\n",
        "\n",
        "        return extracted_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚úó Extraction error: {e}\")\n",
        "        return None\n",
        "\n",
        "def batch_extract_books(books_dict):\n",
        "    \"\"\"Process multiple books and return structured DataFrame\"\"\"\n",
        "\n",
        "    results = []\n",
        "    total_books = len(books_dict)\n",
        "    # Define the expected keys based on the BookMetadata dataclass\n",
        "    expected_keys = [f.name for f in BookMetadata.__dataclass_fields__.values()]\n",
        "\n",
        "\n",
        "    for idx, (book_id, content) in enumerate(books_dict.items(), 1):\n",
        "        print(f\"  üîÑ Processing book {idx}/{total_books}: {book_id}\")\n",
        "\n",
        "        extracted = extract_with_langextract(content)\n",
        "        if extracted:\n",
        "            # Ensure all expected keys are present, fill missing with None\n",
        "            processed_data = {key: extracted.get(key) for key in expected_keys}\n",
        "            processed_data['book_id'] = book_id\n",
        "            results.append(processed_data)\n",
        "            print(f\"    ‚úì Successfully extracted: {extracted.get('title', 'Unknown')}\")\n",
        "            print(f\"    Raw extracted data for {book_id}: {extracted}\") # Added print statement\n",
        "        else:\n",
        "            print(f\"    ‚úó Extraction failed for book: {book_id}\")\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    return df"
      ],
      "metadata": {
        "id": "K3C1pZoETcFA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_uploaded_file(file):\n",
        "    \"\"\"Process uploaded text file through LangExtract\"\"\"\n",
        "\n",
        "    if file is None:\n",
        "        return None, \"Please upload a file\"\n",
        "\n",
        "    # Read file content\n",
        "    content = file.read().decode('utf-8')[:50000]  # Limit to 50k chars\n",
        "\n",
        "    # Extract data\n",
        "    result = extract_with_langextract(content)\n",
        "\n",
        "    if result:\n",
        "        # Convert to DataFrame for display\n",
        "        df = pd.DataFrame([result])\n",
        "\n",
        "        # Create downloadable CSV\n",
        "        csv_buffer = io.StringIO()\n",
        "        df.to_csv(csv_buffer, index=False)\n",
        "        csv_content = csv_buffer.getvalue()\n",
        "\n",
        "        return df, csv_content\n",
        "    else:\n",
        "        return None, \"Extraction failed. Please check your document.\"\n",
        "def create_gradio_app():\n",
        "    \"\"\"Create the Gradio interface for LangExtract\"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"LangExtract Data Extractor\", theme=gr.themes.Soft()) as app:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üìö LangExtract Document Intelligence Platform\n",
        "        ### Transform any document into structured, sellable data in seconds\n",
        "\n",
        "        Upload any text document (books, reports, articles) and watch as AI extracts\n",
        "        valuable structured information instantly.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\"Single Document Extraction\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    file_input = gr.File(\n",
        "                        label=\"Upload Document (.txt)\",\n",
        "                        file_types=[\".txt\"]\n",
        "                    )\n",
        "                    extract_btn = gr.Button(\"üöÄ Extract Data\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column(scale=2):\n",
        "                    output_df = gr.Dataframe(\n",
        "                        label=\"Extracted Structured Data\",\n",
        "                        headers=[\"Field\", \"Value\"],\n",
        "                    )\n",
        "                    download_csv = gr.File(label=\"üì• Download CSV\")\n",
        "\n",
        "            extract_btn.click(\n",
        "                fn=process_uploaded_file,\n",
        "                inputs=file_input,\n",
        "                outputs=[output_df, download_csv]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Batch Processing\"):\n",
        "            gr.Markdown(\"### Process Multiple Documents\")\n",
        "\n",
        "            batch_upload = gr.File(\n",
        "                label=\"Upload Multiple Documents\",\n",
        "                file_count=\"multiple\",\n",
        "                file_types=[\".txt\"]\n",
        "            )\n",
        "\n",
        "            batch_btn = gr.Button(\"üîÑ Process All Documents\", variant=\"primary\")\n",
        "            batch_output = gr.Dataframe(label=\"Batch Results\")\n",
        "            batch_download = gr.File(label=\"üì• Download All Results\")\n",
        "\n",
        "        with gr.Tab(\"Live Demo\"):\n",
        "            gr.Markdown(\"### Try with Sample Books\")\n",
        "\n",
        "            sample_btn = gr.Button(\"üìö Load & Process Sample Books\", variant=\"secondary\")\n",
        "            demo_output = gr.Dataframe(\n",
        "                label=\"Sample Extraction Results\",\n",
        "                value=extracted_df if 'extracted_df' in globals() else None,\n",
        "            )\n",
        "\n",
        "            sample_btn.click(\n",
        "                fn=lambda: extracted_df,\n",
        "                outputs=demo_output\n",
        "            )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        üí° **Business Tip**: Each extracted record can be worth $5-50 when properly\n",
        "        structured and validated. Process 1,000 documents = $5,000-50,000 in data value.\n",
        "\n",
        "        üîó **API Integration**: Export to JSON/CSV for direct integration with your\n",
        "        data products or client systems.\n",
        "        \"\"\")\n",
        "\n",
        "    return app\n",
        "# Launch the app\n",
        "app = create_gradio_app()\n",
        "app.launch(share=True, height=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "40I-t-RkThvE",
        "outputId": "ec9916c2-6215-4434-add2-555f7fd23b65"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8787db1913d1864a33.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8787db1913d1864a33.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Process the downloaded books\n",
        "print(\"\\nüöÄ Starting extraction process...\")\n",
        "extracted_df = batch_extract_books(books_content)\n",
        "print(f\"\\nüìä Successfully extracted data from {len(extracted_df)} books\")\n",
        "\n",
        "# Display sample results\n",
        "if len(extracted_df) > 0:\n",
        "    print(\"\\nüìã Sample extracted data:\")\n",
        "    print(extracted_df[['title', 'author', 'genre']].head())\n",
        "else:\n",
        "    print(\"\\n‚ùå No data extracted. Please check the extraction process.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2aT2L8guT2y4",
        "outputId": "fce1a41f-6913-44fb-97f6-f9fae0008485"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting extraction process...\n",
            "  üîÑ Processing book 1/10: 1342\n",
            "  ‚úó Extraction error: No valid content in response. Full response: response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"MAX_TOKENS\",\n",
            "          \"index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 12492,\n",
            "        \"total_token_count\": 14539,\n",
            "        \"cached_content_token_count\": 11412\n",
            "      },\n",
            "      \"model_version\": \"gemini-2.5-flash\"\n",
            "    }),\n",
            ")\n",
            "    ‚úó Extraction failed for book: 1342\n",
            "  üîÑ Processing book 2/10: 11\n",
            "    ‚úì Successfully extracted: Alice‚Äôs Adventures in Wonderland\n",
            "    Raw extracted data for 11: {'title': 'Alice‚Äôs Adventures in Wonderland', 'author': 'Lewis Carroll', 'publication_year': None, 'main_characters': ['Alice', 'White Rabbit', 'Mouse', 'Dodo', 'Caterpillar'], 'setting_location': 'Wonderland', 'genre': \"Children's Fantasy\", 'plot_summary': \"Bored Alice follows a White Rabbit down a hole into a fantastical world. She experiences rapid changes in size, shrinking after drinking a potion and growing after eating cake, struggling to access a beautiful garden. She cries a pool of tears, then joins a Mouse, Dodo, and other animals in a nonsensical Caucus-Race to dry off. Offending the Mouse by mentioning her cat, Dinah, Alice is later mistaken for the White Rabbit's housemaid. She grows to fill his house, causing chaos, then shrinks and escapes. She encounters a giant puppy before meeting a philosophical Caterpillar smoking a hookah, who challenges her shifting sense of identity.\", 'major_themes': ['Identity', 'Nonsense and Logic', 'Transformation'], 'opening_line': 'Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‚Äúand what is the use of a book,‚Äù thought Alice ‚Äúwithout pictures or conversations?‚Äù', 'target_audience': 'Children and adults who enjoy fantasy and wordplay'}\n",
            "  üîÑ Processing book 3/10: 84\n",
            "    ‚úì Successfully extracted: Frankenstein; or, the Modern Prometheus\n",
            "    Raw extracted data for 84: {'title': 'Frankenstein; or, the Modern Prometheus', 'author': 'Mary Wollstonecraft (Godwin) Shelley', 'publication_year': None, 'main_characters': ['Robert Walton', 'Victor Frankenstein', 'Elizabeth Lavenza', 'Henry Clerval', 'Margaret Saville'], 'setting_location': 'Arctic regions and various European cities (e.g., Geneva, Naples)', 'genre': 'Gothic fiction', 'plot_summary': 'Explorer Robert Walton, on an Arctic voyage, writes to his sister, Margaret, expressing his ambition and loneliness. His ship rescues a dying man, Victor Frankenstein, who is pursuing a gigantic figure. Frankenstein, deeply distressed, warns Walton against dangerous knowledge and agrees to share his tragic tale. The narrative then shifts to Victor\\'s childhood in Geneva, detailing his loving family, his adopted sister Elizabeth Lavenza, and his close friend Henry Clerval. It highlights Victor\\'s early, intense fascination with natural philosophy and forbidden sciences, particularly the works of Cornelius Agrippa, which his father dismisses as \"sad trash,\" inadvertently fueling Victor\\'s dangerous intellectual pursuits.', 'major_themes': ['Dangerous ambition', 'The pursuit of forbidden knowledge', 'Loneliness and isolation'], 'opening_line': 'You will rejoice to hear that no disaster has accompanied the commencement of an enterprise which you have regarded with such evil forebodings.', 'target_audience': 'Adults and young adults interested in classic Gothic literature, early science fiction, and philosophical explorations of ambition and morality.'}\n",
            "  üîÑ Processing book 4/10: 1661\n",
            "    ‚úì Successfully extracted: The Adventures of Sherlock Holmes\n",
            "    Raw extracted data for 1661: {'title': 'The Adventures of Sherlock Holmes', 'author': 'Arthur Conan Doyle', 'publication_year': 2002, 'main_characters': ['Sherlock Holmes', 'Dr. Watson', 'Irene Adler', 'King of Bohemia', 'Godfrey Norton'], 'setting_location': 'London, England', 'genre': 'Detective Fiction', 'plot_summary': \"Dr. Watson narrates a case where Sherlock Holmes is hired by the King of Bohemia to retrieve a compromising photograph from Irene Adler, an American opera singer, before the King's impending marriage. Holmes, known for his keen intellect, devises a plan to discover the photograph's hiding place by staging a fake fire at Irene's London residence. Despite successfully locating the item, Holmes is ultimately outwitted by Irene, who, having married her lawyer, flees to the Continent. She leaves a letter for Holmes, explaining her actions and keeping the photograph as a safeguard, earning Holmes's profound respect for her intelligence and resolve.\", 'major_themes': ['Intellect and Deduction', 'The Battle of Wits', 'Female Agency'], 'opening_line': 'To Sherlock Holmes she is always _the_ woman.', 'target_audience': 'Adults and young adults interested in classic mystery and detective stories.'}\n",
            "  üîÑ Processing book 5/10: 98\n",
            "  ‚úó Extraction error: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
            "    ‚úó Extraction failed for book: 98\n",
            "  üîÑ Processing book 6/10: 844\n",
            "    ‚úì Successfully extracted: The Importance of Being Earnest\n",
            "    Raw extracted data for 844: {'title': 'The Importance of Being Earnest', 'author': 'Oscar Wilde', 'publication_year': 1895, 'main_characters': ['John Worthing', 'Algernon Moncrieff', 'Lady Bracknell', 'Gwendolen Fairfax', 'Cecily Cardew'], 'setting_location': 'London and the English countryside (Woolton, Hertfordshire)', 'genre': 'Comedy', 'plot_summary': \"Jack Worthing, known as Ernest in London, wishes to marry Gwendolen Fairfax. Her cousin, Algernon Moncrieff, uncovers Jack's secret: he maintains a fictional dissolute brother, Ernest, to escape to the city, while in the country, he is guardian to Cecily Cardew. Algernon employs a similar deception, 'Bunburying,' to avoid social obligations. Lady Bracknell, Gwendolen's formidable mother, rejects Jack's proposal due to his mysterious origins, having been found in a handbag at Victoria Station. Jack plans to 'kill off' his fictional brother Ernest, but Algernon, intrigued by Cecily, decides to visit the country posing as Ernest, setting the stage for mistaken identities.\", 'major_themes': ['Deception and Double Lives', 'Marriage and Social Conventions', 'The Nature of Identity'], 'opening_line': 'Did you hear what I was playing, Lane?', 'target_audience': 'Adults interested in satirical comedy, social critique, and classic theatre.'}\n",
            "  üîÑ Processing book 7/10: 2701\n",
            "    ‚úì Successfully extracted: MOBY-DICK; or, THE WHALE.\n",
            "    Raw extracted data for 2701: {'title': 'MOBY-DICK; or, THE WHALE.', 'author': 'Herman Melville', 'publication_year': None, 'main_characters': ['Ishmael', 'Ahab', 'Queequeg', 'Stubb', 'Starbuck'], 'setting_location': 'New Bedford, Nantucket, and the open ocean', 'genre': 'Adventure', 'plot_summary': \"Ishmael, a melancholic landsman, decides to go to sea to cure his 'spleen,' choosing a whaling voyage out of a deep fascination with the ocean and the 'great whale himself.' He arrives in New Bedford, seeking passage to Nantucket, and reflects on humanity's innate connection to water. His journey is driven by an 'everlasting itch for things remote' and the allure of 'forbidden seas.' The narrative introduces his philosophical outlook and his initial search for lodging in a bustling port town, setting the stage for an epic maritime adventure. He anticipates encountering a 'grand hooded phantom, like a snow hill in the air,' hinting at the legendary white whale, Moby Dick.\", 'major_themes': [\"Man's relationship with the sea\", 'The pursuit of the unknown', 'Fate versus free will'], 'opening_line': 'Call me Ishmael.', 'target_audience': 'Adults interested in classic literature, adventure, and philosophical themes'}\n",
            "  üîÑ Processing book 8/10: 345\n",
            "    ‚úì Successfully extracted: DRACULA\n",
            "    Raw extracted data for 345: {'title': 'DRACULA', 'author': 'Bram Stoker', 'publication_year': 1897, 'main_characters': ['Jonathan Harker', 'Count Dracula', 'Mina Murray', 'Lucy Westenra', 'Dr. Seward'], 'setting_location': \"Transylvania, Carpathian Mountains, Count Dracula's Castle\", 'genre': 'Gothic Horror', 'plot_summary': 'Jonathan Harker, an English solicitor, travels to Count Dracula\\'s remote castle in the Carpathian Mountains, Transylvania, to finalize a real estate transaction. His journey is fraught with unsettling superstitions and fearful locals who warn him of evil. Upon arrival, he meets the enigmatic Count, whose appearance and behavior are increasingly strange and unsettling. Harker notes the Count\\'s prodigious strength, cold touch, sharp teeth, and lack of reflection. He discovers locked doors and a lack of mirrors in the castle. As Harker becomes more isolated, he realizes he is a prisoner, growing increasingly fearful of his host and the supernatural horrors hinted at by the locals and the Count\\'s own words about \"children of the night.\"', 'major_themes': ['Supernatural Dread', 'Isolation and Imprisonment', 'Clash of Rationality and Superstition'], 'opening_line': 'How these papers have been placed in sequence will be made manifest in the reading of them.', 'target_audience': 'Adults and young adults interested in classic horror and gothic literature.'}\n",
            "  üîÑ Processing book 9/10: 1232\n",
            "    ‚úì Successfully extracted: The Prince\n",
            "    Raw extracted data for 1232: {'title': 'The Prince', 'author': 'Nicolo Machiavelli', 'publication_year': 1513, 'main_characters': ['Cesare Borgia', 'Louis XII', 'Pope Alexander VI', 'Ferdinand of Aragon', \"Lorenzo de' Medici\"], 'setting_location': 'Italy', 'genre': 'Political Philosophy', 'plot_summary': \"The Prince is a seminal political treatise by Nicolo Machiavelli, offering pragmatic advice to rulers on how to acquire, maintain, and govern principalities. Written in 1513, it analyzes various types of states‚Äîhereditary, new, and mixed‚Äîand the methods for their acquisition and preservation, whether through one's own arms, fortune, or ability. Machiavelli draws extensively on historical examples, particularly from contemporary Italian politics involving figures like Cesare Borgia and Louis XII, to illustrate his theories. The work delves into military strategy, the nature of power, and the qualities a prince needs, often advocating for a ruthless realism where the ends justify the means, prioritizing state stability and security over conventional morality.\", 'major_themes': ['Acquisition and Maintenance of Political Power', 'Pragmatism and Realpolitik', 'Leadership and Statecraft'], 'opening_line': 'All states, all powers, that have held and hold rule over men have been and are either republics or principalities.', 'target_audience': 'Princes, especially new rulers, and students of political theory and statecraft.'}\n",
            "  üîÑ Processing book 10/10: 2591\n",
            "    ‚úì Successfully extracted: Grimms‚Äô Fairy Tales\n",
            "    Raw extracted data for 2591: {'title': 'Grimms‚Äô Fairy Tales', 'author': 'Jacob Grimm and Wilhelm Grimm', 'publication_year': 2001, 'main_characters': [\"Gardener's Youngest Son\", 'Hans', 'Jorinda', 'Ass', 'Sultan'], 'setting_location': 'Various European kingdoms, forests, and villages', 'genre': 'Fairy Tales', 'plot_summary': \"This collection presents various European folk tales, often featuring common people or royalty embarking on quests. Characters encounter magical beings like talking animals, fairies, and witches, facing challenges that test their virtue and wit. Stories include a gardener's son seeking a golden bird with a fox's help, a man trading his way to happiness, lovers separated by an evil fairy, and a group of aging animals forming a band of musicians. Themes of good versus evil, perseverance, and the consequences of choices are prevalent. Transformations, enchanted objects, and moral lessons are key elements, leading to happy endings for the virtuous and punishment for the wicked, reflecting traditional storytelling.\", 'major_themes': ['Good versus Evil', 'Perseverance and Virtue', 'Magic and Enchantment'], 'opening_line': 'A certain king had a beautiful garden, and in the garden stood a tree which bore golden apples.', 'target_audience': 'Children and young adults, as well as adults interested in folklore'}\n",
            "\n",
            "üìä Successfully extracted data from 8 books\n",
            "\n",
            "üìã Sample extracted data:\n",
            "                                     title  \\\n",
            "0         Alice‚Äôs Adventures in Wonderland   \n",
            "1  Frankenstein; or, the Modern Prometheus   \n",
            "2        The Adventures of Sherlock Holmes   \n",
            "3          The Importance of Being Earnest   \n",
            "4                MOBY-DICK; or, THE WHALE.   \n",
            "\n",
            "                                 author               genre  \n",
            "0                         Lewis Carroll  Children's Fantasy  \n",
            "1  Mary Wollstonecraft (Godwin) Shelley      Gothic fiction  \n",
            "2                    Arthur Conan Doyle   Detective Fiction  \n",
            "3                           Oscar Wilde              Comedy  \n",
            "4                       Herman Melville           Adventure  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "cae6a534",
        "outputId": "ea1201de-495c-4291-91d4-c8b89d38a771"
      },
      "source": [
        "# List available models to find a suitable one\n",
        "print(\"üîÑ Listing available Gemini models...\")\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(f\"- {m.name}\")\n",
        "print(\"‚úÖ Finished listing models.\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Listing available Gemini models...\n",
            "- models/gemini-2.5-pro-preview-03-25\n",
            "- models/gemini-2.5-flash-preview-05-20\n",
            "- models/gemini-2.5-flash\n",
            "- models/gemini-2.5-flash-lite-preview-06-17\n",
            "- models/gemini-2.5-pro-preview-05-06\n",
            "- models/gemini-2.5-pro-preview-06-05\n",
            "- models/gemini-2.5-pro\n",
            "- models/gemini-2.0-flash-exp\n",
            "- models/gemini-2.0-flash\n",
            "- models/gemini-2.0-flash-001\n",
            "- models/gemini-2.0-flash-exp-image-generation\n",
            "- models/gemini-2.0-flash-lite-001\n",
            "- models/gemini-2.0-flash-lite\n",
            "- models/gemini-2.0-flash-preview-image-generation\n",
            "- models/gemini-2.0-flash-lite-preview-02-05\n",
            "- models/gemini-2.0-flash-lite-preview\n",
            "- models/gemini-2.0-pro-exp\n",
            "- models/gemini-2.0-pro-exp-02-05\n",
            "- models/gemini-exp-1206\n",
            "- models/gemini-2.0-flash-thinking-exp-01-21\n",
            "- models/gemini-2.0-flash-thinking-exp\n",
            "- models/gemini-2.0-flash-thinking-exp-1219\n",
            "- models/gemini-2.5-flash-preview-tts\n",
            "- models/gemini-2.5-pro-preview-tts\n",
            "- models/learnlm-2.0-flash-experimental\n",
            "- models/gemma-3-1b-it\n",
            "- models/gemma-3-4b-it\n",
            "- models/gemma-3-12b-it\n",
            "- models/gemma-3-27b-it\n",
            "- models/gemma-3n-e4b-it\n",
            "- models/gemma-3n-e2b-it\n",
            "- models/gemini-flash-latest\n",
            "- models/gemini-flash-lite-latest\n",
            "- models/gemini-pro-latest\n",
            "- models/gemini-2.5-flash-lite\n",
            "- models/gemini-2.5-flash-image-preview\n",
            "- models/gemini-2.5-flash-preview-09-2025\n",
            "- models/gemini-2.5-flash-lite-preview-09-2025\n",
            "- models/gemini-robotics-er-1.5-preview\n",
            "‚úÖ Finished listing models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate multiple export formats\n",
        "def create_data_products(df):\n",
        "    \"\"\"Generate various formats for different buyer needs\"\"\"\n",
        "\n",
        "    # JSON for APIs\n",
        "    json_product = df.to_json(orient='records', indent=2)\n",
        "\n",
        "    # CSV for spreadsheet users\n",
        "    csv_product = df.to_csv(index=False)\n",
        "\n",
        "    # SQL for database integration\n",
        "    sql_statements = []\n",
        "    if not df.empty:\n",
        "        for _, row in df.iterrows():\n",
        "            # Convert all values to string and handle potential NaNs\n",
        "            values = []\n",
        "            for v in row.values:\n",
        "                if isinstance(v, list):\n",
        "                    # Convert list to string representation\n",
        "                    str_v = str(v)\n",
        "                elif pd.notna(v): # Check if not NaN for non-list values\n",
        "                     str_v = str(v)\n",
        "                else:\n",
        "                    str_v = '' # Append empty string for NaN non-list values\n",
        "\n",
        "                values.append(str_v)\n",
        "\n",
        "            sql = f\"INSERT INTO book_metadata VALUES ('{', '.join(values)}');\"\n",
        "            sql_statements.append(sql)\n",
        "    sql_product = '\\n'.join(sql_statements)\n",
        "\n",
        "    # Analytics summary\n",
        "    summary = {\n",
        "        'total_records': len(df),\n",
        "        'genres': df['genre'].value_counts().to_dict() if 'genre' in df and 'genre' in df.columns and not df['genre'].dropna().empty else {},\n",
        "        'avg_themes_per_book': df['major_themes'].apply(len).mean() if 'major_themes' in df and 'major_themes' in df.columns and not df['major_themes'].dropna().empty and df['major_themes'].apply(len).sum() > 0 else 0,\n",
        "        'publication_range': f\"{df['publication_year'].min()}-{df['publication_year'].max()}\" if 'publication_year' in df and 'publication_year' in df.columns and not df['publication_year'].dropna().empty else \"N/A\",\n",
        "        'authors': df['author'].nunique() if 'author' in df and 'author' in df.columns and not df['author'].dropna().empty else 0,\n",
        "        'records_value_estimate': f\"${len(df) * 10}-${len(df) * 50}\"\n",
        "    }\n",
        "\n",
        "\n",
        "    return {\n",
        "        'json': json_product,\n",
        "        'csv': csv_product,\n",
        "        'sql': sql_product,\n",
        "        'summary': summary\n",
        "    }\n",
        "# Generate all formats\n",
        "products = create_data_products(extracted_df)\n",
        "print(\"üì¶ Data Products Generated:\")\n",
        "print(f\"  ‚Ä¢ JSON API Feed: {len(products['json'])} bytes\")\n",
        "print(f\"  ‚Ä¢ CSV Database: {len(products['csv'])} bytes\")\n",
        "print(f\"  ‚Ä¢ SQL Import: {len(products['sql'])} bytes\")\n",
        "print(f\"  ‚Ä¢ Analytics Summary: {products['summary']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4qagtcRUQCJ",
        "outputId": "53830ded-eb83-47e3-e410-d5a4c4ec4e60"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Data Products Generated:\n",
            "  ‚Ä¢ JSON API Feed: 11684 bytes\n",
            "  ‚Ä¢ CSV Database: 9506 bytes\n",
            "  ‚Ä¢ SQL Import: 9665 bytes\n",
            "  ‚Ä¢ Analytics Summary: {'total_records': 8, 'genres': {\"Children's Fantasy\": 1, 'Gothic fiction': 1, 'Detective Fiction': 1, 'Comedy': 1, 'Adventure': 1, 'Gothic Horror': 1, 'Political Philosophy': 1, 'Fairy Tales': 1}, 'avg_themes_per_book': np.float64(3.0), 'publication_range': '1513.0-2002.0', 'authors': 8, 'records_value_estimate': '$80-$400'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "output_dir = '/content/drive/MyDrive/LangExtract_Products'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Save all formats\n",
        "with open(f'{output_dir}/books_data.json', 'w') as f:\n",
        "    f.write(products['json'])\n",
        "with open(f'{output_dir}/books_data.csv', 'w') as f:\n",
        "    f.write(products['csv'])\n",
        "with open(f'{output_dir}/books_import.sql', 'w') as f:\n",
        "    f.write(products['sql'])\n",
        "print(f\"‚úÖ Data products saved to Google Drive: {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L1vj8f1dkGU",
        "outputId": "3d370437-f85c-4d76-914d-5da78458dc26"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Data products saved to Google Drive: /content/drive/MyDrive/LangExtract_Products\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Build complete Gradio interface\n",
        "print(\"\\nüé® Building Gradio interface...\")\n",
        "\n",
        "def process_batch_files(files):\n",
        "    \"\"\"Placeholder function for batch processing\"\"\"\n",
        "    # This function will be implemented later\n",
        "    return pd.DataFrame(), None, \"Batch processing is not yet fully implemented.\"\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"LangExtract Data Extractor\", theme=gr.themes.Soft()) as app:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üìö LangExtract Document Intelligence Platform\n",
        "    ### Transform any document into structured, sellable data in seconds\n",
        "\n",
        "    Upload any text document (books, reports, articles) and watch as AI extracts\n",
        "    valuable structured information instantly.\n",
        "\n",
        "    **üí∞ Business Value**: Each extracted record can be worth $10-50 when properly\n",
        "    structured. Process 100 documents = $1,000-5,000 in data value!\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"üéØ Single Document Extraction\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                file_input = gr.File(\n",
        "                    label=\"Upload Document (.txt)\",\n",
        "                    file_types=[\".txt\"]\n",
        "                )\n",
        "                extract_btn = gr.Button(\"üöÄ Extract Data\", variant=\"primary\", size=\"lg\")\n",
        "                status_single = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                output_df = gr.Dataframe(\n",
        "                    label=\"Extracted Structured Data\"\n",
        "                )\n",
        "                download_csv = gr.File(label=\"üì• Download CSV\")\n",
        "\n",
        "        extract_btn.click(\n",
        "            fn=process_uploaded_file,\n",
        "            inputs=file_input,\n",
        "            outputs=[output_df, download_csv, status_single]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üì¶ Batch Processing\"):\n",
        "        gr.Markdown(\"### Process Multiple Documents at Once\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                batch_upload = gr.File(\n",
        "                    label=\"Upload Multiple Documents\",\n",
        "                    file_count=\"multiple\",\n",
        "                    file_types=[\".txt\"]\n",
        "                )\n",
        "                batch_btn = gr.Button(\"üîÑ Process All Documents\", variant=\"primary\", size=\"lg\")\n",
        "                status_batch = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                batch_output = gr.Dataframe(\n",
        "                    label=\"Batch Results\"\n",
        "                )\n",
        "                batch_download = gr.File(label=\"üì• Download All Results\")\n",
        "\n",
        "        batch_btn.click(\n",
        "            fn=process_batch_files,\n",
        "            inputs=batch_upload,\n",
        "            outputs=[batch_output, batch_download, status_batch]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üìä Live Demo\"):\n",
        "        gr.Markdown(\"### Pre-loaded Sample Books from Project Gutenberg\")\n",
        "\n",
        "        demo_output = gr.Dataframe(\n",
        "            label=\"Sample Extraction Results\",\n",
        "            value=extracted_df if len(extracted_df) > 0 else None\n",
        "        )\n",
        "\n",
        "        if len(extracted_df) > 0:\n",
        "            # Generate data products\n",
        "            products = create_data_products(extracted_df)\n",
        "\n",
        "            gr.Markdown(f\"\"\"\n",
        "            ### üìà Data Analytics Summary\n",
        "            - **Total Records**: {products['summary']['total_records']}\n",
        "            - **Unique Authors**: {products['summary']['authors']}\n",
        "            - **Estimated Value**: {products['summary']['records_value_estimate']}\n",
        "            - **Genres Found**: {', '.join(list(products['summary']['genres'].keys())[:5])}\n",
        "            \"\"\")\n",
        "\n",
        "            # Create download links for different formats\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    # Save JSON file\n",
        "                    json_file = \"books_data.json\"\n",
        "                    with open(json_file, 'w') as f:\n",
        "                        f.write(products['json'])\n",
        "                    gr.File(value=json_file, label=\"üìÑ Download JSON\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    # Save SQL file\n",
        "                    sql_file = \"books_import.sql\"\n",
        "                    with open(sql_file, 'w') as f:\n",
        "                        f.write(products['sql'])\n",
        "                    gr.File(value=sql_file, label=\"üóÑÔ∏è Download SQL\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    # Save CSV file\n",
        "                    csv_file = \"books_data.csv\"\n",
        "                    with open(csv_file, 'w') as f:\n",
        "                        f.write(products['csv'])\n",
        "                    gr.File(value=csv_file, label=\"üìä Download CSV\")\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### üí° Business Applications\n",
        "            - Sell to libraries for catalog enrichment\n",
        "            - License to AI training companies\n",
        "            - Create genre-specific book recommendation APIs\n",
        "            - Build literary analysis tools for education\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Tab(\"üí∞ Business Opportunities\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### 20 Profitable Data Extraction Businesses You Can Start Today\n",
        "\n",
        "        #### üè• Healthcare ($5,000-50,000/month potential)\n",
        "        1. **Clinical Trial Database** - Extract from ClinicalTrials.gov\n",
        "        2. **Medical Device Events** - Process FDA MAUDE database\n",
        "        3. **Insurance Requirements** - Structure policy PDFs\n",
        "\n",
        "        #### üèõÔ∏è Government Intelligence ($10,000-100,000/month potential)\n",
        "        4. **Federal Contracts** - Mine SAM.gov requirements\n",
        "        5. **Municipal Minutes** - Extract city council decisions\n",
        "        6. **Grant Matching** - Structure Grants.gov opportunities\n",
        "\n",
        "        #### ‚öñÔ∏è Legal Services ($15,000-150,000/month potential)\n",
        "        7. **Case Law Precedents** - Process Google Scholar decisions\n",
        "        8. **Contract Clauses** - Extract from SEC EDGAR filings\n",
        "        9. **Patent Claims** - Structure USPTO patents\n",
        "\n",
        "        #### üéì Education Market ($3,000-30,000/month potential)\n",
        "        10. **Syllabus Aggregator** - Extract from Open Syllabus\n",
        "        11. **Research Methods** - Mine arXiv papers\n",
        "        12. **Job Requirements** - Analyze HigherEdJobs posts\n",
        "\n",
        "        #### üìà Business Intelligence ($20,000-200,000/month potential)\n",
        "        13. **Earnings Insights** - Process Seeking Alpha transcripts\n",
        "        14. **Review Sentiment** - Structure Amazon reviews\n",
        "        15. **Job Trends** - Analyze LinkedIn postings\n",
        "\n",
        "        #### üöö Supply Chain ($8,000-80,000/month potential)\n",
        "        16. **Shipping Data** - Process ImportYeti documents\n",
        "        17. **Recall Database** - Structure CPSC notices\n",
        "        18. **ESG Metrics** - Extract sustainability reports\n",
        "\n",
        "        #### üéØ Niche Markets ($2,000-20,000/month potential)\n",
        "        19. **Recipe Database** - Extract from food blogs\n",
        "        20. **Real Estate Intel** - Structure Zillow listings\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Start Today**: Pick one niche, extract 100 documents, find 3 buyers.\n",
        "        Scale from there!\n",
        "        \"\"\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    üöÄ **Ready to build your data extraction business?** This platform is your complete toolkit.\n",
        "\n",
        "    üìß Questions? Visit [drlee.io](https://drlee.io) | Built with LangExtract + Gemini\n",
        "    \"\"\")\n",
        "\n",
        "# Launch the application\n",
        "print(\"\\nüöÄ Launching Gradio app...\")\n",
        "print(\"üì± Your app will open in a new tab with a public URL you can share!\")\n",
        "app.launch(share=True)\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ SYSTEM SUCCESSFULLY DEPLOYED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úÖ Books processed: {len(extracted_df)}\")\n",
        "print(f\"üíæ Data ready for export in JSON, CSV, and SQL formats\")\n",
        "print(f\"üåê Share your public URL to demonstrate the system\")\n",
        "print(f\"üí∞ Potential value: ${len(extracted_df) * 10} - ${len(extracted_df) * 50}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "wcYgjXDtfK32",
        "outputId": "0b532495-1fff-4dc4-f221-f0028f525b0e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üé® Building Gradio interface...\n",
            "\n",
            "üöÄ Launching Gradio app...\n",
            "üì± Your app will open in a new tab with a public URL you can share!\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8d910480363fb2fa1b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8d910480363fb2fa1b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üéâ SYSTEM SUCCESSFULLY DEPLOYED!\n",
            "============================================================\n",
            "‚úÖ Books processed: 8\n",
            "üíæ Data ready for export in JSON, CSV, and SQL formats\n",
            "üåê Share your public URL to demonstrate the system\n",
            "üí∞ Potential value: $80 - $400\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}